{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a74e180-b2bf-4758-ac45-368fb8d3b044",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF\n",
    "from pyspark.ml.classification import LogisticRegression, DecisionTreeClassifier, NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Inicjalizacja SparkSession\n",
    "spark = SparkSession.builder.appName(\"SentimentAnalysis\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1a35055d-fdc0-4905-900d-fd74130b2b75",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Zbiór danych - Recenzje filmowe (50 próbek)\n",
    "data = [\n",
    "    (\"I love this movie, it was fantastic!\", 1),\n",
    "    (\"Absolutely terrible, I hated it.\", 0),\n",
    "    (\"Best film I have seen in years.\", 1),\n",
    "    (\"Not worth the time, very disappointing.\", 0),\n",
    "    (\"A wonderful experience, highly recommend!\", 1),\n",
    "    (\"The worst film ever, I regret watching it.\", 0),\n",
    "    (\"An excellent story with great acting.\", 1),\n",
    "    (\"Boring and unoriginal, not worth it.\", 0),\n",
    "    (\"I enjoyed every moment, truly inspiring.\", 1),\n",
    "    (\"Disastrous, a complete waste of time.\", 0),\n",
    "    (\"Pretty decent film, had some great moments.\", 1),\n",
    "    (\"Not my cup of tea, felt dull.\", 0),\n",
    "    (\"An amazing journey, loved the characters.\", 1),\n",
    "    (\"Horrible plot, very predictable.\", 0),\n",
    "    (\"Outstanding performance by the cast!\", 1),\n",
    "    (\"Extremely dull and uninspiring.\", 0),\n",
    "    (\"Brilliantly directed and beautifully shot.\", 1),\n",
    "    (\"Mediocre and forgettable.\", 0),\n",
    "    (\"Thrilling and full of surprises!\", 1),\n",
    "    (\"A pointless sequel, didn't enjoy it.\", 0),\n",
    "    (\"Heartwarming and truly moving.\", 1),\n",
    "    (\"A disaster of a movie, terrible pacing.\", 0),\n",
    "    (\"Beautifully crafted, an absolute gem.\", 1),\n",
    "    (\"Unbearably bad, I couldn't finish it.\", 0),\n",
    "    (\"Engaging and emotionally satisfying.\", 1),\n",
    "    (\"An insult to the original, very poor.\", 0),\n",
    "    (\"Absolutely delightful, a must-watch!\", 1),\n",
    "    (\"Dreadful and poorly executed.\", 0),\n",
    "    (\"Captivating and unforgettable.\", 1),\n",
    "    (\"One of the worst movies I've seen.\", 0),\n",
    "    (\"A masterpiece, truly exceptional.\", 1),\n",
    "    (\"Too slow and boring for my taste.\", 0),\n",
    "    (\"Superb acting and a great storyline.\", 1),\n",
    "    (\"A shallow and poorly written script.\", 0),\n",
    "    (\"Emotionally gripping and powerful.\", 1),\n",
    "    (\"Completely overrated and dull.\", 0),\n",
    "    (\"Inspirational and beautifully told.\", 1),\n",
    "    (\"Amateurish and not worth the watch.\", 0),\n",
    "    (\"A spectacular visual treat!\", 1),\n",
    "    (\"Ridiculously bad, avoid at all costs.\", 0),\n",
    "    (\"An engaging and well-paced thriller.\", 1),\n",
    "    (\"Unoriginal and poorly made.\", 0),\n",
    "    (\"Loved the humor and the clever script.\", 1),\n",
    "    (\"Awful special effects and weak acting.\", 0),\n",
    "    (\"A cinematic triumph, pure joy.\", 1),\n",
    "    (\"Tedious and lacking any charm.\", 0),\n",
    "    (\"Fascinating and thoroughly enjoyable.\", 1),\n",
    "    (\"Terrible dialogue and bad pacing.\", 0)\n",
    "]\n",
    "\n",
    "df = spark.createDataFrame(data, [\"text\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a031704e-3c4f-4b78-a932-e00f06b44d48",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Tokenizacja\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "# Usuwanie stop words\n",
    "stopwords_remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered_words\")\n",
    "# TF-IDF\n",
    "hashing_tf = HashingTF(inputCol=\"filtered_words\", outputCol=\"raw_features\", numFeatures=1000)\n",
    "idf = IDF(inputCol=\"raw_features\", outputCol=\"features\")\n",
    "\n",
    "# Modele klasyfikacyjne\n",
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\")\n",
    "dt = DecisionTreeClassifier(featuresCol=\"features\", labelCol=\"label\")\n",
    "nb = NaiveBayes(featuresCol=\"features\", labelCol=\"label\")\n",
    "\n",
    "# Tworzenie pipeline\n",
    "pipeline_lr = Pipeline(stages=[tokenizer, stopwords_remover, hashing_tf, idf, lr])\n",
    "pipeline_dt = Pipeline(stages=[tokenizer, stopwords_remover, hashing_tf, idf, dt])\n",
    "pipeline_nb = Pipeline(stages=[tokenizer, stopwords_remover, hashing_tf, idf, nb])\n",
    "\n",
    "# Podział na zbiór treningowy i testowy\n",
    "train_df, test_df = df.randomSplit([0.7, 0.3], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c3259237-5bbe-449f-ac16-1dbc4385ff25",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liczba próbek w zbiorze testowym: 16\nPredykcje dla regresji logistycznej:\n+--------------------+-----+----------+\n|                text|label|prediction|\n+--------------------+-----+----------+\n|Best film I have ...|    1|       0.0|\n|An excellent stor...|    1|       1.0|\n|Pretty decent fil...|    1|       1.0|\n|An amazing journe...|    1|       1.0|\n|Brilliantly direc...|    1|       1.0|\n|Horrible plot, ve...|    0|       1.0|\n|Mediocre and forg...|    0|       1.0|\n|A disaster of a m...|    0|       0.0|\n|Beautifully craft...|    1|       1.0|\n|A shallow and poo...|    0|       1.0|\n|Completely overra...|    0|       0.0|\n|Too slow and bori...|    0|       0.0|\n|Amateurish and no...|    0|       0.0|\n|An engaging and w...|    1|       1.0|\n|Ridiculously bad,...|    0|       1.0|\n|Fascinating and t...|    1|       1.0|\n+--------------------+-----+----------+\n\nPredykcje dla drzewa decyzyjnego:\n+--------------------+-----+----------+\n|                text|label|prediction|\n+--------------------+-----+----------+\n|Best film I have ...|    1|       0.0|\n|An excellent stor...|    1|       0.0|\n|Pretty decent fil...|    1|       0.0|\n|An amazing journe...|    1|       0.0|\n|Brilliantly direc...|    1|       0.0|\n|Horrible plot, ve...|    0|       0.0|\n|Mediocre and forg...|    0|       0.0|\n|A disaster of a m...|    0|       0.0|\n|Beautifully craft...|    1|       0.0|\n|A shallow and poo...|    0|       0.0|\n|Completely overra...|    0|       0.0|\n|Too slow and bori...|    0|       0.0|\n|Amateurish and no...|    0|       0.0|\n|An engaging and w...|    1|       0.0|\n|Ridiculously bad,...|    0|       0.0|\n|Fascinating and t...|    1|       0.0|\n+--------------------+-----+----------+\n\nPredykcje dla Naive Bayes:\n+--------------------+-----+----------+\n|                text|label|prediction|\n+--------------------+-----+----------+\n|Best film I have ...|    1|       0.0|\n|An excellent stor...|    1|       1.0|\n|Pretty decent fil...|    1|       1.0|\n|An amazing journe...|    1|       1.0|\n|Brilliantly direc...|    1|       1.0|\n|Horrible plot, ve...|    0|       1.0|\n|Mediocre and forg...|    0|       1.0|\n|A disaster of a m...|    0|       0.0|\n|Beautifully craft...|    1|       1.0|\n|A shallow and poo...|    0|       0.0|\n|Completely overra...|    0|       0.0|\n|Too slow and bori...|    0|       0.0|\n|Amateurish and no...|    0|       0.0|\n|An engaging and w...|    1|       1.0|\n|Ridiculously bad,...|    0|       1.0|\n|Fascinating and t...|    1|       1.0|\n+--------------------+-----+----------+\n\nAccuracy - Logistic Regression: 0.69\nAccuracy - Decision Tree: 0.50\nAccuracy - Naive Bayes: 0.75\nPrecision - Logistic Regression: 0.72\nRecall - Logistic Regression: 0.69\nF1 Score - Logistic Regression: 0.68\nNajbardziej wpływowe indeksy cech:\n[(7, -3.660461505422447), (587, 3.2005964112263308), (687, 3.2005964112263308), (805, -3.1037175131646784), (335, 3.085990005086027), (893, 3.085990005086027), (720, 3.045001052074931), (897, 3.045001052074931), (52, 3.0450010520749236), (627, 3.0450010520749236)]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Liczba próbek w zbiorze testowym: {test_df.count()}\")\n",
    "if test_df.count() == 0:\n",
    "    print(\"Błąd: zbiór testowy jest pusty! Zwiększ liczbę danych.\")\n",
    "else:\n",
    "    # Trenowanie modeli\n",
    "    model_lr = pipeline_lr.fit(train_df)\n",
    "    model_dt = pipeline_dt.fit(train_df)\n",
    "    model_nb = pipeline_nb.fit(train_df)\n",
    "\n",
    "    # Predykcje\n",
    "    test_predictions_lr = model_lr.transform(test_df)\n",
    "    test_predictions_dt = model_dt.transform(test_df)\n",
    "    test_predictions_nb = model_nb.transform(test_df)\n",
    "\n",
    "    print(\"Predykcje dla regresji logistycznej:\")\n",
    "    test_predictions_lr.select(\"text\", \"label\", \"prediction\").show()\n",
    "    print(\"Predykcje dla drzewa decyzyjnego:\")\n",
    "    test_predictions_dt.select(\"text\", \"label\", \"prediction\").show()\n",
    "    print(\"Predykcje dla Naive Bayes:\")\n",
    "    test_predictions_nb.select(\"text\", \"label\", \"prediction\").show()\n",
    "\n",
    "    evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", metricName=\"accuracy\")\n",
    "    accuracy_lr = evaluator.evaluate(test_predictions_lr)\n",
    "    accuracy_dt = evaluator.evaluate(test_predictions_dt)\n",
    "    accuracy_nb = evaluator.evaluate(test_predictions_nb)\n",
    "    print(f\"Accuracy - Logistic Regression: {accuracy_lr:.2f}\")\n",
    "    print(f\"Accuracy - Decision Tree: {accuracy_dt:.2f}\")\n",
    "    print(f\"Accuracy - Naive Bayes: {accuracy_nb:.2f}\")\n",
    "\n",
    "    # Precision, Recall, F1-score\n",
    "    evaluator_precision = MulticlassClassificationEvaluator(labelCol=\"label\", metricName=\"weightedPrecision\")\n",
    "    evaluator_recall = MulticlassClassificationEvaluator(labelCol=\"label\", metricName=\"weightedRecall\")\n",
    "    evaluator_f1 = MulticlassClassificationEvaluator(labelCol=\"label\", metricName=\"f1\")\n",
    "    \n",
    "    print(f\"Precision - Logistic Regression: {evaluator_precision.evaluate(test_predictions_lr):.2f}\")\n",
    "    print(f\"Recall - Logistic Regression: {evaluator_recall.evaluate(test_predictions_lr):.2f}\")\n",
    "    print(f\"F1 Score - Logistic Regression: {evaluator_f1.evaluate(test_predictions_lr):.2f}\")\n",
    "    \n",
    "    # Analiza wag cech dla regresji logistycznej\n",
    "    lr_model = model_lr.stages[-1]\n",
    "    if hasattr(lr_model, \"coefficients\"):\n",
    "        feature_importance = sorted(zip(range(len(lr_model.coefficients.toArray())), lr_model.coefficients.toArray()), key=lambda x: abs(x[1]), reverse=True)\n",
    "        print(\"Najbardziej wpływowe indeksy cech:\")\n",
    "        print(feature_importance[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "506c63d9-4adf-45db-bd86-99eda4aff6a9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "1. **Predykcje na zbiorze testowym:**\n",
    "\n",
    "W zbiorze testowym widać, że regresja logistyczna poprawnie przewidziała etykiety dla niektórych przykładów, ale popełniła również błędy. Przykładowo:\n",
    "\n",
    "    \"Mediocre and forgettable\" miało etykietę prawdziwą 0 (negatywną), ale zostało przewidziane jako 1 (pozytywne).\n",
    "    \"Ridiculously bad, avoid at all costs\" również zostało błędnie sklasyfikowane jako 1 zamiast 0.\n",
    "\n",
    "Błędy te wskazują, że model może mieć trudności z rozpoznawaniem negatywnych opinii, szczególnie jeśli są one wyrażone w sposób mniej dosadny lub jeśli zawierają słowa mogące sugerować pozytywny kontekst.\n",
    "\n",
    "2.** Metryki dla regresji logistycznej:**\n",
    "\n",
    "    Accuracy (dokładność): 0.69\n",
    "    Oznacza, że model poprawnie sklasyfikował 69% próbek testowych.\n",
    "    Precision (precyzja): 0.72\n",
    "    Spośród wszystkich przykładów przewidzianych jako pozytywne (1), 72% było poprawnych.\n",
    "    Precyzja sugeruje, że model unika fałszywych alarmów (błędnych przewidywań pozytywnych).\n",
    "    Recall (czułość): 0.69\n",
    "    Spośród wszystkich rzeczywistych przykładów pozytywnych, model poprawnie sklasyfikował 69%.\n",
    "    Niższa czułość oznacza, że model mógł pominąć część pozytywnych próbek.\n",
    "    F1 Score: 0.68\n",
    "    F1-score jest zbalansowaną miarą, która uwzględnia zarówno precyzję, jak i czułość. Wynik wskazuje, że model ma średnią skuteczność w klasyfikacji pozytywnych przykładów.\n",
    "\n",
    "3. **Analiza wpływu cech (ważność cech):**\n",
    "\n",
    "Najbardziej wpływowe indeksy cech dla regresji logistycznej to:\n",
    "\n",
    "    Cechy o najwyższej wartości dodatniej:\n",
    "        Indeks 587, 687, 335, 893, 720, 897, 52, 627 (wartości w przedziale ~3.0–3.2)\n",
    "        Te cechy (prawdopodobnie odpowiadające specyficznym słowom w tekście) mają największy pozytywny wpływ na przewidywanie klasy 1 (pozytywne opinie).\n",
    "        Interpretacja: Model traktuje te cechy jako silne wskaźniki pozytywnego sentymentu.\n",
    "\n",
    "    Cechy o najwyższej wartości ujemnej:\n",
    "        Indeks 7 (-3.66), 805 (-3.10)\n",
    "        Te cechy mają największy negatywny wpływ, czyli silnie wskazują na klasę 0 (negatywne opinie).\n",
    "        Interpretacja: Model postrzega te cechy jako silne wskaźniki negatywnego sentymentu.\n",
    "\n",
    "4. **Porównanie z innymi modelami:**\n",
    "\n",
    "    Decision Tree (Accuracy: 0.50):\n",
    "    Drzewo decyzyjne wykazało się niższą skutecznością. Jego dokładność sugeruje, że działa ono losowo przy tak małym zbiorze testowym. Drzewa decyzyjne mogą być mniej skuteczne w klasyfikacji danych tekstowych bez dostatecznej ilości danych treningowych.\n",
    "\n",
    "    Naive Bayes (Accuracy: 0.75):\n",
    "    Model Naive Bayes osiągnął najlepszą dokładność. Jest to zgodne z oczekiwaniami, ponieważ Naive Bayes często sprawdza się w zadaniach klasyfikacji tekstu, szczególnie przy małych zbiorach danych.\n",
    "\n",
    "5. **Ogólna interpretacja:**\n",
    "\n",
    "Regresja logistyczna radzi sobie dobrze, ale ma trudności z poprawnym klasyfikowaniem niektórych próbek negatywnych, co wpływa na precyzję i czułość. Warto zwrócić uwagę na najbardziej wpływowe cechy i upewnić się, że dane wejściowe są wystarczająco bogate w reprezentatywne słowa dla obu klas (pozytywnych i negatywnych)."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Projekt - Sentimental Analysis",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
